Y
Y<-cbind(X,rnorm(5))
Y
Y<-cbind(X,rnorm(2))
Y<-cbind(X,rnorm(7))
Y<-cbind(X,rnorm(5))
Y
Y<-cbind(rnorm(5),X)
Y
Y<-rbind(rnorm(5),X)
Y
Y<-rbind(X,rnorm(5))
Y
install.packages("RPostgreSQL")
require(RPostgreSQL)
rm(list=ls(all=TRUE))
data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
data <- download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile='data.csv')
data<-read.csv("data.csv")
View(data)
agricultureLogical <- (survey$ACR == 3 & survey$AGS == 6)
agricultureLogical <- (data$ACR == 3 & data$AGS == 6)
which(agricultureLogical)
library("jpeg")
install.packages("jpeg")
library(jpeg)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg",destfile='pic.jpg')
picture <- readJPEG('pic.jpg', native = TRUE)
quantile(picture, c(0.3, 0.8))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile='gdp.csv')
gdp<-read.csv("gdp.csv")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile='edu.csv')
edu<-read.csv("edu.csv")
View(edu)
View(gdp)
merged <- merge(gdp, edu, all = TRUE, by = "CountryCode")
View(edu)
gdp <- read.csv(fname, skip = 4, nrows = 215) %>%
subset(!is.na(X) & X != "", select = c("X", "X.1", "X.3", "X.4")) %>%
rename(CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
gdp <- read.csv("gdp.csv", skip = 4, nrows = 215) %>% subset(!is.na(X) & X != "", select = c("X", "X.1", "X.3", "X.4")) %>% rename(CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
gdp <- read.csv("gdp.csv", skip = 4, nrows = 215)
gdp <- subset(gdp,!is.na(X) & X != "", select = c("X", "X.1", "X.3", "X.4"))
gdp <- rename(gdp,CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
library(dplyr)
gdp <- rename(gdp,CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
View(gdp)
merged <- merge(gdp, edu, all = TRUE, by = "CountryCode")
sum(!is.na(unique(merged$rankingGDP)))
sorted <- subset(merged, select = c(rankingGDP, Long.Name.x))
sorted[order(answer3.2$rankingGDP, decreasing = TRUE), "Long.Name.x"][13]
sorted[order(sorted$rankingGDP, decreasing = TRUE), "Long.Name.x"][13]
avg_rank <- function(label) {
income_group <- subset(merged, merged$Income.Group == label)
mean(as.numeric(income_group$rankingGDP), na.rm = TRUE)
}
answer4.oecd <- avg_rank("High income: OECD")
answer4.non.oecd <- avg_rank("High income: nonOECD")
msg("High income OECD:", answer4.oecd, "High income nonOECD:", answer4.non.oecd)
answer4.oecd
answer4.non.oecd
DT <- subset(merged, select = c(Income.Group, rankingGDP)) %>%
mutate(quantileGDP = cut2(rankingGDP, g = 5)) %>%
data.table
install.packages("Hmisc")
library(Hmisc)
DT <- subset(merged, select = c(Income.Group, rankingGDP)) %>%
mutate(quantileGDP = cut2(rankingGDP, g = 5)) %>%
data.table
library(data.table)
DT <- subset(merged, select = c(Income.Group, rankingGDP)) %>%
mutate(quantileGDP = cut2(rankingGDP, g = 5)) %>%
data.table
View(DT)
answer5 <- DT[Income.Group == "Lower middle income", .N,
by = c("Income.Group", "quantileGDP")] %>%
subset(quantileGDP == "[  1, 39)", select = N)
View(answer5)
library(swirl)
swirl()
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
View(cran)
cran
help(group_by())
help(group_by)
by_package <- group_by(cran,"package")
by_package <- group_by(cran,package)
by_package
summarize(by_package,mean(size))
View(by_package)
summarize(by_package,mean(size))
info()
summarize(by_package,size=mean(size))
help("summarize")
library(plyr)
library(Hmisc)
summarize(by_package,size=mean(size))
summarize(by_package,mean(size))
by_package <- group_by(cran,package)
package
by_package
tbl_df
pack_sum <- summarize(by_package,
count = n() ,
unique = n_distinct(ip_id) ,
countries = n_distinct(country) ,
avg_bytes = mean(size))
pack_sum <- summarize(by_package,
unique = n_distinct(ip_id) ,
countries = n_distinct(country) ,
avg_bytes = mean(size))
pack_sum
pack_sum <- summarize(by_package,
count = n() ,
unique = n_distinct(ip_id) ,
countries = n_distinct(country) ,
avg_bytes = mean(size))
detach("package:plyr", unload=TRUE)
pack_sum <- summarize(by_package,
count = n() ,
unique = n_distinct(ip_id) ,
countries = n_distinct(country) ,
avg_bytes = mean(size))
library(dplyr)
pack_sum <- summarize(by_package,
count = n() ,
unique = n_distinct(ip_id) ,
countries = n_distinct(country) ,
avg_bytes = mean(size))
pack_sum <- summarise(by_package,
count = n() ,
unique = n_distinct(ip_id) ,
countries = n_distinct(country) ,
avg_bytes = mean(size))
pack_sum
submit()
submit()
submit()
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count>679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts,desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs =0.99)
top_unique <- filter(pack_sum, unique>465)
View(top_unique)
top_unique_sorted <- arrange(top_unique,desc(count))
top_unique_sorted <- arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
submit()
submit()
submit()
submit()
View(result3)
cran %>%
select() %>%
print
submit()
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
View(students2)
gather(students2, sex_class, count, -grade)
res <- gather(students2, sex_class, count, -grade)
res
?separate
separate(data = res, col = sex_class, into = c("sex", "class"))
submit()
students3
submit()
?spread
submit()
library(readr)
parse_number("class5").
?parse_number
parse_number(class5).
parse_number
parse_number("$1000")
parse_number("sgsg1000")
parse_number("class1000")
parse_number("class5")
submit()
submit()
students4
getwd()
submit()
submit()
submit()
passed
failed
mutate(passed,status="passed")
passed <- passed %>% mutate(status = "passed")
failed <- failed %>% mutate(status = "failed")
packageVersion('dplyr')
bind_rows(passed, failed)
sat
submit()
?group_by
submit()
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day,label = TRUE)
this_moment<- now()
this_moment
hour(this_moment)
my_date <- ymd("1989-05-17")
my_date
class(my_date)
ymd("1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd(192012)
ymd("1920/1/2")
dt1
ymd_hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment<-update(now(),hours = 15, minutes = 44)
this_moment
nyc<-now(Zone="America/New_York")
?now
nyc<-now(tone="America/New_York")
nyc<-now(tzone="America/New_York")
nyc
depart <- nyc + days(2)
depart
depart <- updtate(depart,hours = 17, minutes = 34)
depart <- update(depart,hours = 17, minutes = 34)
depart
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive <- with_tz(arrive, tzone = "Asia/Hong_Kong")
arrive
last_time <- mdy("June 17, 2008",tz = "Singapore")
last_time
?interval
how_long <- interval(last_time,arrive)
as.period(how_long)
stopwatch()
fname <- "survey.csv"
download_if_not_exists(fname, "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv")
survey_df <- read.csv(fname, header = TRUE, sep = ",")
fname <- "survey4.csv"
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",destfile=fname)
survey_df <- read.csv(fname, header = TRUE, sep = ",")
strsplit(names(survey_df), "wgtp")[[123]]
fname ="dgp4.scv"
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile=fname)
gdp <- read.csv(fname, skip = 4, nrows = 215) %>%
subset(!is.na(X) & X != "", select = c("X", "X.1", "X.3", "X.4")) %>%
rename(CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
gdp <- read.csv(fname, skip = 4, nrows = 215) %>%
subset(!is.na(X) & X != "", select = c("X", "X.1", "X.3", "X.4")) %>%
rename(CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
library(dplyr)
library(plyr)
library(Hmisc)
gdp <- read.csv(fname, skip = 4, nrows = 215) %>%
subset(!is.na(X) & X != "", select = c("X", "X.1", "X.3", "X.4")) %>%
rename(CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
gdp <- read.csv(fname, skip = 4, nrows = 215) %>%
subset(!is.na(X) & X != "", select = c("X", "X.1", "X.3", "X.4"))
gsub(",", "", gdp$X.4) %>%
as.numeric %>%
mean(na.rm = TRUE)
grep("*United",countryNames), 2
countryNames <- gdp$X.3
grep("^United",countryNames)
countryNames
grep("^China",countryNames)
grep("^Isle",countryNames)
fname ="dgp5.scv"
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv",destfile=fname)
edu <- read.csv(fname, header = TRUE, sep = ",")
# Match the data based on the country shortcode
merged <- merge(gdp, edu, all = TRUE, by = "CountryCode")
gdp <- read.csv(fname, header = TRUE, sep = ",")
fname ="edu5.csv"
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv",destfile=fname)
edu <- read.csv(fname, header = TRUE, sep = ",")
colnames(edu)
colnames(gdp)
gdp <- rename(gdp,CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
library(dplyr)
gdp <- rename(gdp,CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
detach("plyr")
detach(plyr)
detach("package:plyr", unload=TRUE)
detach("package:dplyr", unload=TRUE)
gdp <- rename(gdp,CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
library(dplyr)
gdp <- rename(gdp,CountryCode = X, rankingGDP = X.1, Long.Name = X.3, gdp = X.4)
merged <- merge(gdp, edu, all = TRUE, by = "CountryCode")
answer4 <- "fiscal year end.*june" %>%
grep(merged$Special.Notes %>% tolower) %>%
length
answer4
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
amzn
sampleTimes
colnames(sampleTimes)
length(sampleTimes)
nrow(amzn)
dtype(amzn)
class(amzn)
DF <- table(Year = year(sampleTimes), weekdays(sampleTimes)) %>%
addmargins(FUN = list(Total = sum), quiet = TRUE) %>%
as.data.frame
DF
colnames(DF) <- c("Year", "Value", "Count")
DF
filterDF <- function(value) {
subset(DF, Year == 2012 & Value == value, select = Count)
}
filterDF("Total")
filterDF("Monday")
setwd("~/cleaning-data")
source("run_analysis.R")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip",destfile='data')
unzip ("data.zip", exdir = "./")
unzip ("data", exdir = "./")
rm(list = ls())
library(dplyr)
#library(plyr)
library(Hmisc)
data_dir <- "UCI HAR Dataset"
## Load features as human-readable column names
features <- load_file("features.txt", data_dir)
## Load activity labels
activity_lbls <- load_file("activity_labels.txt", data_dir)
file.path("usr", "local", "lib")
data_dir <- "UCI HAR Dataset"
file.path(data_dir, "lib,txt")
features <- read.table(file.path(data_dir, "features.txt"),header = FALSE)
View(features)
activity_lbls <- read.table(file.path(data_dir, "activity_labels.txt"),header = FALSE)
## Load training data
tain_data <- read.table(file.path(data_dir, "train", "X_train.txt"),header = FALSE)
## Load test data
test_data <- read.table(file.path(data_dir, "test", "X_test.txt"),header = FALSE)
test_data <- read.table(file.path(data_dir, "test", "y_test.txt"),header = FALSE)
## Load test subs
test_data <- read.table(file.path(data_dir, "test", "subject_test.txtt"),header = FALSE)
test_data <- read.table(file.path(data_dir, "test", "X_test.txt"),header = FALSE)
## Load test labels
test_lbls <- read.table(file.path(data_dir, "test", "y_test.txt"),header = FALSE)
## Load test subs
test_subs <- read.table(file.path(data_dir, "test", "subject_test.txt"),header = FALSE)
## Load training labels
tain_lbls <- read.table(file.path(data_dir, "train", "y_train.txt"),header = FALSE)
## Load training subs
tain_subs<- read.table(file.path(data_dir, "train", "subject_train.txt"),header = FALSE)
names(test_subs)
names(test_subs) <- "Subject"
names(test_subs)
names(tain_subs)
names(tain_subs) <- "Subject"
rm(tain_data)
rm(tain_lbls)
rm(tain_subs)
train_data <- read.table(file.path(data_dir, "train", "X_train.txt"),header = FALSE)
## Adjusts column names
## Load training labels
train_lbls <- read.table(file.path(data_dir, "train", "y_train.txt"),header = FALSE)
## Adjusts column name
## Load training subs
train_subs<- read.table(file.path(data_dir, "train", "subject_train.txt"),header = FALSE)
## Adjusts column name
names(train_subs) <- "Subject"
names(features)
features$V2
colm_names <- gsub("-", "_", features$V2)
colm_names <- gsub("[^a-zA-Z\\d_]", "", colm_names)
colm_names
names(test_data)
names(test_data) <- make.names(names = colm_names, unique = TRUE, allow_ = TRUE)
names(train_data) <- make.names(names = colm_names, unique = TRUE, allow_ = TRUE)
names(test_data)
names(train_lbls)
names(train_lbls) <- "Activity"
train_lbls$Activity <- factor(train_lbls$Activity, levels = activity_lbls$V1, labels = activity_lbls$V2)
names(test_lbls) <- "Activity"
test_lbls$Activity <- factor(test_lbls$Activity, levels = activity_lbls$V1, labels = activity_lbls$V2)
test_lbls$Activity
merged_data <- rbind(
cbind(train_data, train_lbls, train_subs),
cbind(test_data, test_lbls, test_subs)
)
merged_data <- select(merged_data,
matches("mean|std"),
one_of("Subject", "Activity")
)
View(merged_data)
id_cols <- c("Subject", "Activity")
tidy_data <- melt(
merge_data,
id = id_cols,
measure.vars = setdiff(colnames(merge_data), id_cols)
)
library(reshape)
id_cols <- c("Subject", "Activity")
tidy_data <- melt(
merge_data,
id = id_cols,
measure.vars = setdiff(colnames(merge_data), id_cols)
)
tidy_data <- melt(
merged_data,
id = id_cols,
measure.vars = setdiff(colnames(merged_data), id_cols)
)
tidy_data <-dcast(tidy_data,Subject + Activity ~ variable, mean)
library(reshape2)
tidy_data <-dcast(tidy_data,Subject + Activity ~ variable, mean)
rm(list = ls())l
rm(list = ls())
####### Load Data & Adjust Column Names#############
data_dir <- "UCI HAR Dataset"
## Load features
features <- read.table(file.path(data_dir, "features.txt"),header = FALSE)
#getting column names
colm_names <- gsub("-", "_", features$V2)
colm_names <- gsub("[^a-zA-Z\\d_]", "", colm_names)
## Load activity labels
activity_lbls <- read.table(file.path(data_dir, "activity_labels.txt"),header = FALSE)
####### Load training data
train_data <- read.table(file.path(data_dir, "train", "X_train.txt"),header = FALSE)
## Adjusts column names
names(train_data) <- make.names(names = colm_names, unique = TRUE, allow_ = TRUE)
## Load training labels
train_lbls <- read.table(file.path(data_dir, "train", "y_train.txt"),header = FALSE)
## Adjusts column names
names(train_lbls) <- "Activity"
#Uses descriptive activity names to name the activities in the data set
train_lbls$Activity <- factor(train_lbls$Activity, levels = activity_lbls$V1, labels = activity_lbls$V2)
## Load training subs
train_subs<- read.table(file.path(data_dir, "train", "subject_train.txt"),header = FALSE)
## Adjusts column names
names(train_subs) <- "Subject"
#######  Load test data
test_data <- read.table(file.path(data_dir, "test", "X_test.txt"),header = FALSE)
## Adjusts column names
names(test_data) <- make.names(names = colm_names, unique = TRUE, allow_ = TRUE)
## Load test labels
test_lbls <- read.table(file.path(data_dir, "test", "y_test.txt"),header = FALSE)
## Adjusts column names
names(test_lbls) <- "Activity"
#Uses descriptive activity names to name the activities in the data set
test_lbls$Activity <- factor(test_lbls$Activity, levels = activity_lbls$V1, labels = activity_lbls$V2)
## Load test subs
test_subs <- read.table(file.path(data_dir, "test", "subject_test.txt"),header = FALSE)
## Adjusts column names
names(test_subs) <- "Subject"
##############################################################
#Merges the training and the test sets to create one data set.
merged_data <- rbind(
cbind(train_data, train_lbls, train_subs),
cbind(test_data, test_lbls, test_subs)
)
##############################################################
#Extracts only the measurements on the mean and standard deviation for each measurement.
merged_data <- select(merged_data,
matches("mean|std"),
one_of("Subject", "Activity")
)
id_cols <- c("Subject", "Activity")
tidy_data <- melt(
merged_data,
id = id_cols,
measure.vars = setdiff(colnames(merged_data), id_cols)
)
tidy_data <-dcast(tidy_data,Subject + Activity ~ variable, mean)
?search
search()
(.packages())
rm(list = ls(all = TRUE))
(.packages())
loadedNamespaces()
require(nothing, quietly = TRUE)
loadedNamespaces()
